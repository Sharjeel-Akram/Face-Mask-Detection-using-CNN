{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A tough time has been passed through that was of COVID. During this time everything was at stake. People started wearing mask to prevent themselves from this pandemic. But it was needed to make an application to detect who is wearing mask and who is without mask.\n",
        "So, people built up a simple and basic Convolutional Neural Network (CNN) model using TensorFlow with Keras library and OpenCV to detect if you are wearing a face mask to protect yourself.\n",
        "\n",
        "Tensorflow is an open source library for fast numerical computing. \n",
        "First of all I installed tensorflowjs library using the pip command."
      ],
      "metadata": {
        "id": "RlZ3M08sIfLK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkDQhgWkFMkM"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the tensorflowjs library for python, now it was the time to upload the data to my google drive which was connected to this foogle colab account. Fisrt, I uploaded the complete dataset of 1376 images in which 690 images are with mask and 689 images are without mask. After uploading the data set i mounted my drive using google colab library drive. I gave the link to my drive and then mount this drive."
      ],
      "metadata": {
        "id": "gmzCz9OZKYau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txntet7M62Xy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I created an empty array named trainingDataset for each image which will be appended in this array.\n",
        "Another variable classNumber is defined which means that each image belongs to which class either it is with mask or without mask.\n",
        "Another variable is constant variable named as img_size with value of 100. \n",
        "I copied the path of my dataset and stored that path in path variable."
      ],
      "metadata": {
        "id": "IZDB0WWLLJAM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1x1YwLiM648v"
      },
      "outputs": [],
      "source": [
        "trainingDataset = []\n",
        "classNumber = 0\n",
        "img_size = 100\n",
        "path = \"/content/drive/MyDrive/dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell I imported some libraries of python. \n",
        "One is keras which is used for building up a model for machine learning that is sequential model. I imported keras layers of Conv2D, MaxPooling2D, Dense, Dropout, Activation and Flatten. \n",
        "I imported cv2 library for image read and numpy library for the arrays and os library for the directories."
      ],
      "metadata": {
        "id": "eaUorPyNME3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "XzQs4d7v68JB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflowjs as tfjs\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell I have read all the images with its class number and stored them in the form of tuple in the trainingdataset array. \n",
        "In forst line of code I cleared all the values in dataset. and then to check how many classes are there I applied a loop to check classes and there is nested loop in which I read each image using Cv2 in each class and converted it into the grey scale because these images were colorful and then reshape it with the fixed size of img_size which I defined in the above code cell. At the end I appended the image and its class label as a tuple in the array. And did an increment in the class number to check an other directory for an other class. \n",
        "To check the output I printed training dataset like its length, length of first element and first element of trainingdataset."
      ],
      "metadata": {
        "id": "Nvw7-v4LM2rU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "B4ql94Cf7BJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ad587b-ab62-4f1f-9093-3673cb749da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1376\n",
            "2\n",
            "[array([[0.87372549, 0.94729412, 0.94096471, ..., 0.97647059, 0.96862745,\n",
            "        0.81976516],\n",
            "       [0.92698038, 0.93443138, 0.92494903, ..., 0.98039216, 0.96862745,\n",
            "        0.80611788],\n",
            "       [0.87098036, 0.91898039, 0.91921572, ..., 0.97647059, 0.97569421,\n",
            "        0.77652565],\n",
            "       ...,\n",
            "       [0.17621193, 0.17254902, 0.16666589, ..., 0.15019531, 0.22155402,\n",
            "        0.14523387],\n",
            "       [0.15113724, 0.13709099, 0.15959904, ..., 0.13428141, 0.16595182,\n",
            "        0.17662665],\n",
            "       [0.16949019, 0.14884842, 0.19076863, ..., 0.06860391, 0.13297004,\n",
            "        0.15459312]]), 0]\n"
          ]
        }
      ],
      "source": [
        "trainingDataset.clear()\n",
        "for folder in (os.listdir(path)):\n",
        "  print(classNumber)\n",
        "  fp = os.path.join(path,folder)\n",
        "  for eachImage in os.listdir(fp):\n",
        "    imagePath = os.path.join(fp,eachImage)\n",
        "    img = (cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE))/255\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    trainingDataset.append([img,classNumber])\n",
        "  classNumber = classNumber + 1\n",
        "\n",
        "print(len(trainingDataset))\n",
        "print(len(trainingDataset[0]))\n",
        "print(trainingDataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell, I made two empty lists named as X and Y. I shuffled randomly the tariningdataset and then I applied the for loop on randomized trainingdataset and appended images features or images read array in the X list and Its label or classnumber in the Y list."
      ],
      "metadata": {
        "id": "U1WEYnW0Nj2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbJVKc2_7AhP",
        "outputId": "fc907456-9f6e-41fb-c043-3682739a7e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "Y = []\n",
        "img_size = 100\n",
        "np.random.shuffle(trainingDataset)\n",
        "for features, label in trainingDataset:\n",
        "    X.append(features)\n",
        "    Y.append(label)\n",
        "print(Y)    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell, I reshaped the features array in the single column. I used to categorical function of keras library to convert a class vector to binary matrix which means class 0 will be [1,0] and class 1 will be [0,1].\n",
        " "
      ],
      "metadata": {
        "id": "EEmF5M7EOBsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ktc0O07Gys",
        "outputId": "3b36e656-fc3a-4093-c2a1-62fb448930fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
        "Y_binary = to_categorical(Y)\n",
        "print(Y_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell, I built up an model of sequential using CNN. \n",
        "In first line I defined the model which is sequential. Then I added the layer of Conv2D which creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. Conv2D has first argument that is filter an integer which is number of output filters. Then second is kernal size means 2x2 size window from the image which is to be convolved. and at the end input shape which is tuple of integers of input image size. Then is used activartion function for input layer that is 'relu' which means rectified linear unit which converts all negative values to 0. An other layer is MaxPooling2D which gets the maximum number from the poolsize of matrix. Then There is Dropout which  randomly sets input units to 0 with a frequency of of input at each step during training time, which helps prevent overfitting. There i defined 10% of input will be zero.\n",
        "\n",
        "Then I added a Flatten layer which converts a 2D array or matrix in a single array. \n",
        "\n",
        "Then I used ouput layer named as Dense layer which is used to classify image based on output from convolutional layers.\n",
        "\n",
        "In output layer, I used the 'softmax' activation function. Softmax function is used when there are 2 or more than 2 classes. The number of neurons will be 100 and then 2. It is mainly used to normalize neural networks output to fit between zero and one."
      ],
      "metadata": {
        "id": "dih0weIeO5Xw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GaLfSKvJ6uuG"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(40, (2, 2), input_shape=(100,100,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(60, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(80, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        " \n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After building up model using some input layers and two output layers I comiled my model. I used binary_categorical because our dataset contans only two classes. and I used optizer adam and we can use sgd instead of adam and any other. At the last for matrics I used accuracy to check the accuracy of training data with its labels."
      ],
      "metadata": {
        "id": "HVqcZFzbSk-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "zkGkwx4V7Hem"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell, I fit my training data with its features and binary labels. Batch_size was of 32 and epochs was 10 which means there are ten iteration and each iteration 32 batches are trained. I used the validation split = 0.2 which means it will tell us validation accuracy after each traing phase."
      ],
      "metadata": {
        "id": "M1ymwoXKTVMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-1MXwF87PvD",
        "outputId": "b805f7ef-2601-40e0-f7c4-0a48254d2fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "35/35 [==============================] - 1s 24ms/step - loss: 0.6971 - accuracy: 0.5473 - val_loss: 0.6567 - val_accuracy: 0.6377\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.5727 - accuracy: 0.7073 - val_loss: 0.4899 - val_accuracy: 0.7971\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.3975 - accuracy: 0.8155 - val_loss: 0.3993 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.2606 - accuracy: 0.9100 - val_loss: 0.3688 - val_accuracy: 0.8297\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.2135 - accuracy: 0.9255 - val_loss: 0.3009 - val_accuracy: 0.8986\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.1763 - accuracy: 0.9409 - val_loss: 0.2961 - val_accuracy: 0.8841\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.1257 - accuracy: 0.9609 - val_loss: 0.2068 - val_accuracy: 0.9312\n",
            "Epoch 8/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.1066 - accuracy: 0.9709 - val_loss: 0.2241 - val_accuracy: 0.9203\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0857 - accuracy: 0.9709 - val_loss: 0.1641 - val_accuracy: 0.9420\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0846 - accuracy: 0.9691 - val_loss: 0.1620 - val_accuracy: 0.9457\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17d0167d50>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "model.fit(X, Y_binary,\n",
        "          batch_size = 32,\n",
        "          epochs=10, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the function to prepare an image which will further be used to validate my model. Again here I used cv2 library to read the image and then resize it of shape 100x100. and then return the image to predict function."
      ],
      "metadata": {
        "id": "pMz5PrglTvWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "86Mq1nka7Sxs"
      },
      "outputs": [],
      "source": [
        "def prepare(filepath):\n",
        "    img_size = 100 \n",
        "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)/255  \n",
        "    img_resize = cv2.resize(img, (img_size, img_size))  \n",
        "    return img_resize.reshape(-1, img_size, img_size, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code cell I predict an image and checked that from which class it belongs, There is a variable category which is a list of strings in which each class is of one string. and there is an argmax which maps the prediction of each class. "
      ],
      "metadata": {
        "id": "teAhg0T-T579"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zYm-mQV7WQT",
        "outputId": "2caa3a97-165f-4b3a-c7eb-fd8867523c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.9996793e-01 3.2118864e-05]]\n",
            "With Mask\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(prepare(\"/content/drive/MyDrive/Mask Test/2-with-mask.jpg\"))\n",
        "print((prediction))\n",
        "\n",
        "CATEGORIES = [\"With Mask\", \"Without Mask\"]\n",
        "\n",
        "pred_class = CATEGORIES[np.argmax(prediction)]\n",
        "print(pred_class)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Face Mask Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}